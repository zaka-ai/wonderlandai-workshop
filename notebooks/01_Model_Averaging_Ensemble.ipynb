{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Model_Averaging_Ensemble",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch86Jzzg_dXO",
        "colab_type": "text"
      },
      "source": [
        "## Model Averaging Ensemble\n",
        "\n",
        "We can use model averaging to both reduce the variance of the model and possibly reduce the generalization error of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu3W6KYZUQZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start with the imports\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnPVTM9fUmM_",
        "colab_type": "text"
      },
      "source": [
        "First, we must develop a function to prepare and return a fit model on the training dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4143vc5UnIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit model on dataset\n",
        "def fit_model(trainX, trainy):\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(15, input_dim=2, activation='relu'))\n",
        "\tmodel.add(Dense(3, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# fit model\n",
        "\tmodel.fit(trainX, trainy, epochs=200, verbose=0)\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTLpmDyFUpFT",
        "colab_type": "text"
      },
      "source": [
        "Next, we need a function that can take a list of ensemble members and make a prediction for an out-of-sample dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0WTqQE_Vhfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make an ensemble prediction for multi-class classification\n",
        "def ensemble_predictions(members, testX):\n",
        "\t# make predictions\n",
        "\tyhats = [model.predict(testX) for model in members]\n",
        "\tyhats = array(yhats)\n",
        "\t# sum across ensemble members\n",
        "\tsummed = numpy.sum(yhats, axis=0)\n",
        "\t# argmax across classes\n",
        "\tresult = argmax(summed, axis=1)\n",
        "\treturn result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5LV-cOrVk0E",
        "colab_type": "text"
      },
      "source": [
        "We donâ€™t know how many ensemble members will be appropriate for this problem. Therefore, we can perform a sensitivity analysis of the number of ensemble members and how it impacts test accuracy. This means we need a function that can evaluate a specified number of ensemble members and return the accuracy of a prediction combined from those members."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhpwHtgQVp1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate a specific number of members in an ensemble\n",
        "def evaluate_n_members(members, n_members, testX, testy):\n",
        "\t# select a subset of members\n",
        "\tsubset = members[:n_members]\n",
        "\tprint(len(subset))\n",
        "\t# make prediction\n",
        "\tyhat = ensemble_predictions(subset, testX)\n",
        "\t# calculate accuracy\n",
        "\treturn accuracy_score(testy, yhat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuAibWHvVvEn",
        "colab_type": "text"
      },
      "source": [
        "Next we create the dataset, split into train and test, and fit all models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvDlyPY0_WYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate 2d classification dataset\n",
        "X, y = make_blobs(n_samples=500, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
        "# split into train and test\n",
        "n_train = int(0.3 * X.shape[0])\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "trainy = to_categorical(trainy)\n",
        "\n",
        "# fit all models\n",
        "n_members = 20\n",
        "members = [fit_model(trainX, trainy) for _ in range(n_members)]\n",
        "\n",
        "# evaluate different numbers of ensembles\n",
        "scores = list()\n",
        "for i in range(1, n_members+1):\n",
        "\tscore = evaluate_n_members(members, i, testX, testy)\n",
        "\tprint('> %.3f' % score)\n",
        "\tscores.append(score)\n",
        " \n",
        "# plot score vs number of ensemble members\n",
        "x_axis = [i for i in range(1, n_members+1)]\n",
        "pyplot.plot(x_axis, scores)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MenZJ9ro_twk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Based on the previous experiment, we can see that performance improves to about **five members**, after which performance plateaus around 76% accuracy. We can update the repeated evaluation experiment to use an ensemble of five models instead of a single model and compare the distribution of scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht1r1hAl_xjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# repeated evaluation of model averaging ensemble on blobs dataset\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import numpy\n",
        "\n",
        "# fit model on dataset\n",
        "def fit_model(trainX, trainy):\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(15, input_dim=2, activation='relu'))\n",
        "\tmodel.add(Dense(3, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# fit model\n",
        "\tmodel.fit(trainX, trainy, epochs=200, verbose=0)\n",
        "\treturn model\n",
        "\n",
        "# make an ensemble prediction for multi-class classification\n",
        "def ensemble_predictions(members, testX):\n",
        "\t# make predictions\n",
        "\tyhats = [model.predict(testX) for model in members]\n",
        "\tyhats = array(yhats)\n",
        "\t# sum across ensemble members\n",
        "\tsummed = numpy.sum(yhats, axis=0)\n",
        "\t# argmax across classes\n",
        "\tresult = argmax(summed, axis=1)\n",
        "\treturn result\n",
        "\n",
        "# evaluate ensemble model\n",
        "def evaluate_members(members, testX, testy):\n",
        "\t# make prediction\n",
        "\tyhat = ensemble_predictions(members, testX)\n",
        "\t# calculate accuracy\n",
        "\treturn accuracy_score(testy, yhat)\n",
        "\n",
        "# generate 2d classification dataset\n",
        "X, y = make_blobs(n_samples=500, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
        "\n",
        "# split into train and test\n",
        "n_train = int(0.3 * X.shape[0])\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "trainy = to_categorical(trainy)\n",
        "\n",
        "# repeated evaluation\n",
        "n_repeats = 10 \n",
        "n_members = 5\n",
        "scores = list()\n",
        "\n",
        "for _ in range(n_repeats):\n",
        "\t# fit all models\n",
        "\tmembers = [fit_model(trainX, trainy) for _ in range(n_members)]\n",
        "\t# evaluate ensemble\n",
        "\tscore = evaluate_members(members, testX, testy)\n",
        "\tprint('> %.3f' % score)\n",
        "\tscores.append(score)\n",
        "\n",
        "# summarize the distribution of scores\n",
        "print('Scores Mean: %.3f, Standard Deviation: %.3f' % (mean(scores), std(scores)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}